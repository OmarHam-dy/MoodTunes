{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F94A213520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F94A213520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 178, in detect_emotion\n",
      "    image = self.preprocess_image(self.file_path)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 167, in preprocess_image\n",
      "    image = cv2.resize(image, (224, 224))\n",
      "cv2.error: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 178, in detect_emotion\n",
      "    image = self.preprocess_image(self.file_path)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 167, in preprocess_image\n",
      "    image = cv2.resize(image, (224, 224))\n",
      "cv2.error: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 178, in detect_emotion\n",
      "    image = self.preprocess_image(self.file_path)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 167, in preprocess_image\n",
      "    image = cv2.resize(image, (224, 224))\n",
      "cv2.error: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 178, in detect_emotion\n",
      "    image = self.preprocess_image(self.file_path)\n",
      "  File \"C:\\Users\\egymo\\AppData\\Local\\Temp\\ipykernel_14224\\2985881692.py\", line 167, in preprocess_image\n",
      "    image = cv2.resize(image, (224, 224))\n",
      "cv2.error: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import pygame\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import DepthwiseConv2D\n",
    "\n",
    "# Custom function to handle unsupported 'groups' argument in DepthwiseConv2D\n",
    "def custom_depthwise_conv2d(*args, **kwargs):\n",
    "    kwargs.pop(\"groups\", None)  # Remove 'groups' if present\n",
    "    return DepthwiseConv2D(*args, **kwargs)\n",
    "\n",
    "# Load the model with custom handling for DepthwiseConv2D\n",
    "custom_objects = {\"DepthwiseConv2D\": custom_depthwise_conv2d}\n",
    "model = load_model(r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\best_model.h5\", custom_objects=custom_objects, compile=False)\n",
    "\n",
    "# Save the modified model (optional)\n",
    "model.save('modified_model.h5')\n",
    "\n",
    "class EmotionDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Emotion Detection App\")\n",
    "        self.root.geometry(\"900x700\")\n",
    "\n",
    "        # Center the application window on the screen\n",
    "        window_width = 650\n",
    "        window_height = 600\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        position_top = int(screen_height / 2 - window_height / 2)\n",
    "        position_right = int(screen_width / 2 - window_width / 2)\n",
    "        self.root.geometry(f\"{window_width}x{window_height}+{position_right}+{position_top}\")\n",
    "\n",
    "        # Initialize pygame for music\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        # Load your emotion detection model\n",
    "        self.model = model  # Use the modified model\n",
    "\n",
    "        # Define emotion-to-music mapping\n",
    "        self.emotion_to_music = {\n",
    "            \"Angry\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\angry_song.mp3\",\n",
    "            \"Disguist\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\Disguist  Disguist_song.mp3\",\n",
    "            \"Fear\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\Fear_song.mp3.mp3\",\n",
    "            \"Happy\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\pharrell_williams_-_happy_(official_music_video).mp3\",\n",
    "            \"Neutral\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\Neutral_song.mp3\",\n",
    "            \"Sad\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\Sad_song.mp3\",\n",
    "            \"Surprise\": r\"C:\\Users\\egymo\\Desktop\\ML_Project\\Project\\Surprise_song.mp3\",\n",
    "        }\n",
    "\n",
    "        # GUI Components\n",
    "        self.is_paused = False  # State to track whether the music is paused\n",
    "\n",
    "        # Top frame for title\n",
    "        self.top_frame = tk.Frame(root, bg=\"navy\", height=100)\n",
    "        self.top_frame.pack(fill=tk.X)\n",
    "\n",
    "        self.title_label = tk.Label(self.top_frame, text=\"Emotion Detection App\", font=(\"Helvetica\", 24, \"bold\"), fg=\"white\", bg=\"navy\")\n",
    "        self.title_label.pack(pady=20)\n",
    "\n",
    "        # Main frame for content\n",
    "        self.main_frame = tk.Frame(root, bg=\"lightgray\")\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)\n",
    "\n",
    "        # Photo display\n",
    "        self.photo_label = tk.Label(self.main_frame, text=\"Photo will appear here\", bg=\"white\", width=40, height=15, relief=\"solid\", borderwidth=2)\n",
    "        self.photo_label.grid(row=0, column=0, columnspan=3, padx=20, pady=10)\n",
    "\n",
    "        # Buttons\n",
    "        self.upload_button = tk.Button(self.main_frame, text=\"Attach Photo\", command=self.attach_photo, bg=\"dodgerblue\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        self.upload_button.grid(row=1, column=0, padx=20, pady=10)\n",
    "\n",
    "        self.detect_button = tk.Button(self.main_frame, text=\"Detect Emotion\", command=self.detect_emotion, bg=\"green\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        self.detect_button.grid(row=1, column=1, padx=20, pady=10)\n",
    "\n",
    "        self.webcam_button = tk.Button(self.main_frame, text=\"Open Webcam\", command=self.capture_from_webcam, bg=\"orange\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        self.webcam_button.grid(row=1, column=2, padx=20, pady=10)\n",
    "\n",
    "        self.pause_button = tk.Button(self.main_frame, text=\"Pause Music\", command=self.pause_music, bg=\"yellow\", font=(\"Arial\", 12), width=15)\n",
    "        self.pause_button.grid(row=2, column=0, padx=20, pady=10)\n",
    "\n",
    "        self.resume_button = tk.Button(self.main_frame, text=\"Resume Music\", command=self.resume_music, bg=\"green\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        self.resume_button.grid(row=2, column=1, padx=20, pady=10)\n",
    "\n",
    "        self.stop_button = tk.Button(self.main_frame, text=\"Stop Music\", command=self.stop_music, bg=\"red\", fg=\"white\", font=(\"Arial\", 12, \"bold\"), width=15)\n",
    "        self.stop_button.grid(row=2, column=2, padx=20, pady=10)\n",
    "\n",
    "        # Emotion result\n",
    "        self.result_label = tk.Label(self.main_frame, text=\"Emotion: None\", font=(\"Helvetica\", 18), bg=\"lightgray\")\n",
    "        self.result_label.grid(row=3, column=0, columnspan=3, pady=20)\n",
    "\n",
    "        # Status label\n",
    "        self.status_label = tk.Label(self.main_frame, text=\"Status: Ready\", font=(\"Helvetica\", 14), bg=\"lightgray\")\n",
    "        self.status_label.grid(row=4, column=0, columnspan=3, pady=10)\n",
    "\n",
    "        # Configure grid layout\n",
    "        self.main_frame.grid_columnconfigure(0, weight=1)\n",
    "        self.main_frame.grid_columnconfigure(1, weight=1)\n",
    "        self.main_frame.grid_columnconfigure(2, weight=1)\n",
    "\n",
    "    def attach_photo(self):\n",
    "        self.file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg\")])\n",
    "        if self.file_path:\n",
    "            try:\n",
    "                image = Image.open(self.file_path)\n",
    "                image.thumbnail((300, 300))\n",
    "                photo = ImageTk.PhotoImage(image)\n",
    "                self.photo_label.configure(image=photo, text=\"\")\n",
    "                self.photo_label.image = photo\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Failed to load image: {e}\")\n",
    "\n",
    "    def capture_from_webcam(self):\n",
    "        # Open the default camera .\n",
    "        cam = cv2.VideoCapture(0)\n",
    "\n",
    "        # Create a window named \"Webcam\" to display the video feed.\n",
    "        cv2.namedWindow(\"Webcam\")\n",
    "\n",
    "        # Initialize a counter to keep track of the number of screenshots taken.\n",
    "        img_counter = 0\n",
    "\n",
    "        # infinite loop to continuously capture frames from the webcam.\n",
    "        while True:\n",
    "        # Capture a single frame from the webcam. `ret` indicates if the capture was successful, \n",
    "        # and `frame` contains the captured image.\n",
    "            ret, frame = cam.read()\n",
    "\n",
    "            # If `ret` is False, it means the frame was not successfully captured.\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")  \n",
    "                break  # Exit the loop if frame capture fails.\n",
    "\n",
    "            # Display the captured frame in the \"Webcam\" window.\n",
    "            cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "            # stores the ASCII value of the key pressed.\n",
    "            k = cv2.waitKey(1) & 0xFF == ord('q')\n",
    "\n",
    "            # Check if the Esc key (ASCII value 27) was pressed.\n",
    "            if k % 256 == 27:\n",
    "                print(\"Esc hit, closing the app\")  \n",
    "                break  \n",
    "\n",
    "            # Check if the Space key (ASCII value 32) was pressed.\n",
    "            elif k % 256 == 32:\n",
    "                # Create a filename for the screenshot using the counter value.\n",
    "                img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "\n",
    "                # Save the current frame as an image file with the generated filename.\n",
    "                cv2.imwrite(img_name, frame)\n",
    "                print(\"Screenshot taken\")\n",
    "\n",
    "                # Increment the screenshot counter for the next file name.\n",
    "                img_counter += 1\n",
    "                \n",
    "\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def preprocess_image(self, file_path):\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = image / 255.0\n",
    "        if len(image.shape) == 2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[-1] == 1:\n",
    "            image = np.repeat(image, 3, axis=-1)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        return image\n",
    "\n",
    "    def detect_emotion(self):\n",
    "        if hasattr(self, \"file_path\"):\n",
    "            image = self.preprocess_image(self.file_path)\n",
    "            prediction = self.model.predict(image)\n",
    "            emotion_index = np.argmax(prediction)\n",
    "            emotion_classes = [\"Angry\", \"Disguist\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "            if emotion_index < len(emotion_classes):\n",
    "                detected_emotion = emotion_classes[emotion_index]\n",
    "                self.result_label.config(text=f\"Emotion: {detected_emotion}\")\n",
    "                self.play_music(detected_emotion)\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"Invalid emotion detected. Please check your model and classes.\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Error\", \"No photo uploaded!\")\n",
    "\n",
    "    def play_music(self, emotion):\n",
    "        if emotion in self.emotion_to_music:\n",
    "            music_file = self.emotion_to_music[emotion]\n",
    "            pygame.mixer.music.load(music_file)\n",
    "            pygame.mixer.music.play()\n",
    "        else:\n",
    "            messagebox.showinfo(\"Info\", \"No music available for this emotion.\")\n",
    "\n",
    "    def pause_music(self):\n",
    "        if pygame.mixer.music.get_busy() and not self.is_paused:\n",
    "            pygame.mixer.music.pause()\n",
    "            self.is_paused = True\n",
    "            self.status_label.config(text=\"Status: Music Paused\")\n",
    "\n",
    "    def resume_music(self):\n",
    "        if self.is_paused:\n",
    "            pygame.mixer.music.unpause()\n",
    "            self.is_paused = False\n",
    "            self.status_label.config(text=\"Status: Music Resumed\")\n",
    "        elif not pygame.mixer.music.get_busy():\n",
    "            self.status_label.config(text=\"Status: No music to resume\")\n",
    "\n",
    "    def stop_music(self):\n",
    "        if pygame.mixer.music.get_busy():\n",
    "            pygame.mixer.music.stop()\n",
    "            self.is_paused = False\n",
    "            self.status_label.config(text=\"Status: Music Stopped\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = EmotionDetectionApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
